interactions:
- request:
    body: '{"model": "tgi", "messages": "please output ''Observation''", "frequency_penalty":
      null, "logit_bias": null, "logprobs": null, "max_tokens": 200, "n": null, "presence_penalty":
      null, "seed": null, "stop": ["Observation", "Final Answer"], "temperature":
      null, "tool_choice": null, "tool_prompt": null, "tools": null, "top_logprobs":
      null, "top_p": null, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '367'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - 52f7edcd-57c0-4258-8ff1-e3c520a43ef7
      user-agent:
      - unknown/None; hf_hub/0.23.0.dev0; python/3.10.12; torch/2.2.1; tensorflow/2.15.0.post1;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-70B-Instruct/v1/chat/completions
  response:
    body:
      string: 'Failed to deserialize the JSON body into the target type: messages:
        invalid type: string "please output ''Observation''", expected a sequence
        at line 1 column 58'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - text/plain; charset=utf-8
      Date:
      - Mon, 29 Apr 2024 16:18:50 GMT
      Transfer-Encoding:
      - chunked
      access-control-allow-credentials:
      - 'true'
      access-control-allow-origin:
      - '*'
      vary:
      - origin, Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-request-id:
      - yECOxGeXLet5-Ae5rw808
      x-sha:
      - e8cf5276ae3e97cfde8a058e64a636f2cde47820
    status:
      code: 422
      message: Unprocessable Entity
version: 1
