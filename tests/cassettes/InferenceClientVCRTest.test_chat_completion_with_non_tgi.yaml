interactions:
- request:
    body: '{"model": "tgi", "messages": [{"role": "system", "content": "You are a
      helpful assistant."}, {"role": "user", "content": "What is deep learning?"}],
      "frequency_penalty": null, "logit_bias": null, "logprobs": null, "max_tokens":
      20, "n": null, "presence_penalty": null, "seed": null, "stop": null, "temperature":
      null, "tool_choice": null, "tool_prompt": null, "tools": null, "top_logprobs":
      null, "top_p": null, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '428'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - 0f793623-22a8-48a6-834b-81b58b19b92c
      user-agent:
      - unknown/None; hf_hub/0.23.0.dev0; python/3.10.12; torch/2.2.1; tensorflow/2.15.0.post1;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/microsoft/DialoGPT-small/v1/chat/completions
  response:
    body:
      string: '{"error":"unknown error","warnings":["There was an inference error:
        unknown error: can only concatenate str (not \"dict\") to str"]}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Apr 2024 10:49:22 GMT
      Transfer-Encoding:
      - chunked
      access-control-allow-credentials:
      - 'true'
      access-control-expose-headers:
      - x-compute-type, x-compute-time
      server:
      - uvicorn
      vary:
      - Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-time:
      - '0.001'
      x-compute-type:
      - cpu
      x-request-id:
      - 2-JgFiFGmvDDPzJchhq6a
      x-sha:
      - 49c537161a457d5256512f9d2d38a87d81ae0f0e
    status:
      code: 500
      message: Internal Server Error
- request:
    body: '{"inputs": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is deep learning?"}], "parameters": {"do_sample":
      false, "max_new_tokens": 20, "return_full_text": false, "stop": []}, "stream":
      false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '244'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - 5493238e-8215-44d9-a30d-02bbe8d8fee2
      user-agent:
      - unknown/None; hf_hub/0.23.0.dev0; python/3.10.12; torch/2.2.1; tensorflow/2.15.0.post1;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/microsoft/DialoGPT-small
  response:
    body:
      string: '{"error":"The following `model_kwargs` are not used by the model: [''stop'']
        (note: typos in the generate arguments will also show up in this list)","warnings":["There
        was an inference error: The following `model_kwargs` are not used by the model:
        [''stop''] (note: typos in the generate arguments will also show up in this
        list)"]}'
    headers:
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Apr 2024 10:49:22 GMT
      Transfer-Encoding:
      - chunked
      access-control-allow-credentials:
      - 'true'
      access-control-expose-headers:
      - x-compute-type, x-compute-time
      server:
      - uvicorn
      vary:
      - Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-time:
      - '0.002'
      x-compute-type:
      - cpu
      x-request-id:
      - KBkATPrqJyS7FlCaYnrWK
      x-sha:
      - 49c537161a457d5256512f9d2d38a87d81ae0f0e
    status:
      code: 400
      message: Bad Request
- request:
    body: '{"inputs": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is deep learning?"}], "parameters": {"do_sample":
      false, "max_new_tokens": 20, "return_full_text": false}, "stream": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, br
      Connection:
      - keep-alive
      Content-Length:
      - '232'
      Content-Type:
      - application/json
      X-Amzn-Trace-Id:
      - 5fb6d7d3-1604-4957-9111-0a737c90e69b
      user-agent:
      - unknown/None; hf_hub/0.23.0.dev0; python/3.10.12; torch/2.2.1; tensorflow/2.15.0.post1;
        fastcore/1.5.23
    method: POST
    uri: https://api-inference.huggingface.co/models/microsoft/DialoGPT-small
  response:
    body:
      string: '[{"generated_text":"Deep learning is a thing."}]'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '48'
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Apr 2024 10:49:22 GMT
      access-control-allow-credentials:
      - 'true'
      vary:
      - Origin, Access-Control-Request-Method, Access-Control-Request-Headers
      x-compute-time:
      - '0.146'
      x-compute-type:
      - cache
      x-request-id:
      - xueA4XZTpX7lVK8Imy-Ys
      x-sha:
      - 49c537161a457d5256512f9d2d38a87d81ae0f0e
    status:
      code: 200
      message: OK
version: 1
